{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration      5K - Error: 14.837315\n",
      "Iteration     10K - Error: 13.815009\n",
      "Iteration     15K - Error: 13.256886\n",
      "Iteration     20K - Error: 12.698159\n",
      "Iteration     25K - Error: 12.168479\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-ee92a45550f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[0mlnErr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-1\u001b[0m  \u001b[1;31m#1e-6 0.1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlnMax\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m         \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbpn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrainEpoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlvTarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.02\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m5000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#5000\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Iteration {0:6d}K - Error: {1:0.6f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-ee92a45550f4>\u001b[0m in \u001b[0;36mTrainEpoch\u001b[1;34m(self, input, target, trainingRate, momentum)\u001b[0m\n\u001b[0;32m    134\u001b[0m                 \u001b[1;31m# Compare to the following layer's delta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m                 \u001b[0mdelta_pullback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m                 \u001b[0mdelta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta_pullback\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtFuncs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_layerInput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;31m# Compute weight deltas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-ee92a45550f4>\u001b[0m in \u001b[0;36mtanh\u001b[1;34m(x, Derivative)\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtruncLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDerivative\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#\n",
    "# Transfer functions\n",
    "#\n",
    "class TransferFunctions:\n",
    "    def sgm(x, Derivative=False):\n",
    "        if not Derivative:\n",
    "            return 1.0 / (1.0 + np.exp(-x))\n",
    "        else:\n",
    "            #out = sgm(x)\n",
    "            out = 1.0 / (1.0 + np.exp(-x))\n",
    "            return out * (1.0 - out)\n",
    "    \n",
    "    def linear(x, Derivative=False):\n",
    "        if not Derivative:\n",
    "            return x\n",
    "        else:\n",
    "            return 1.0\n",
    "    \n",
    "    def gaussian(x, Derivative=False):\n",
    "        if not Derivative:\n",
    "            return np.exp(-x**2)\n",
    "        else:\n",
    "            return -2*x*np.exp(-x**2)\n",
    "    \n",
    "    def tanh(x, Derivative=False):\n",
    "        if not Derivative:\n",
    "            return np.tanh(x)\n",
    "        else:\n",
    "            return 1.0 - np.tanh(x)**2\n",
    "    \n",
    "    def truncLinear(x, Derivative=False):\n",
    "        if not Derivative:\n",
    "            y = x.copy()\n",
    "            y[y < 0] = 0\n",
    "            return y\n",
    "        else:\n",
    "            return 1.0\n",
    "        \n",
    "#\n",
    "# Classes\n",
    "#\n",
    "class BackPropagationNetwork:\n",
    "    \"\"\"A back-propagation network\"\"\"\n",
    "    \n",
    "    #\n",
    "    # Class methods\n",
    "    #\n",
    "    def __init__(self, layerSize, layerFunctions=None):\n",
    "        \"\"\"Initialize the network\"\"\"\n",
    "        \n",
    "        self.layerCount = 0\n",
    "        self.shape = None\n",
    "        self.weights = []\n",
    "        self.tFuncs = []\n",
    "        \n",
    "        # Layer info\n",
    "        self.layerCount = len(layerSize) - 1\n",
    "        self.shape = layerSize\n",
    "        \n",
    "        if layerFunctions is None:\n",
    "            lFuncs = []\n",
    "            for i in range(self.layerCount):\n",
    "                if i == self.layerCount - 1:\n",
    "                    lFuncs.append(TransferFunctions.linear)\n",
    "                else:\n",
    "                    lFuncs.append(TransferFunctions.sgm)\n",
    "        else:\n",
    "            if len(layerSize) != len(layerFunctions):\n",
    "                raise ValueError(\"Incompatible list of transfer functions.\")\n",
    "            elif layerFunctions[0] is not None:\n",
    "                raise ValueError(\"Input layer cannot have a transfer function.\")\n",
    "            else:\n",
    "                lFuncs = layerFunctions[1:]\n",
    "        \n",
    "        self.tFuncs = lFuncs\n",
    "        \n",
    "        # Data from last Run\n",
    "        self._layerInput = []\n",
    "        self._layerOutput = []\n",
    "        self._previousWeightDelta = []\n",
    "        \n",
    "        # Create the weight arrays\n",
    "        for (l1,l2) in zip(layerSize[:-1], layerSize[1:]):\n",
    "            self.weights.append(np.random.normal(scale=0.01, size = (l2, l1+1)))\n",
    "            self._previousWeightDelta.append(np.zeros((l2, l1+1)))\n",
    "    \n",
    "    #\n",
    "    # Run method\n",
    "    #\n",
    "    def Run(self, input):\n",
    "        \"\"\"Run the network based on the input data\"\"\"\n",
    "        \n",
    "        lnCases = input.shape[0]\n",
    "        \n",
    "        # Clear out the previous intermediate value lists\n",
    "        self._layerInput = []\n",
    "        self._layerOutput = []\n",
    "        \n",
    "        # Run it!\n",
    "        for index in range(self.layerCount):\n",
    "            # Determine layer input\n",
    "            if index == 0:\n",
    "                layerInput = self.weights[0].dot(np.vstack([input.T, np.ones([1, lnCases])]))\n",
    "            else:\n",
    "                layerInput = self.weights[index].dot(np.vstack([self._layerOutput[-1], np.ones([1, lnCases])]))\n",
    "            \n",
    "            self._layerInput.append(layerInput)\n",
    "            self._layerOutput.append(self.tFuncs[index](layerInput))\n",
    "        \n",
    "        return self._layerOutput[-1].T\n",
    "                 \n",
    "    #\n",
    "    # TrainEpoch method\n",
    "    #\n",
    "    def TrainEpoch(self, input, target, trainingRate = 0.01, momentum = 0.7): #trainingRate = 0.02, momentum = 0.5\n",
    "        \"\"\"This method trains the network for one epoch\"\"\"\n",
    "        \n",
    "        delta = []\n",
    "        lnCases = input.shape[0]\n",
    "        \n",
    "        # First run the network\n",
    "        self.Run(input)\n",
    "        \n",
    "        # Calculate our deltas\n",
    "        for index in reversed(range(self.layerCount)):\n",
    "            if index == self.layerCount - 1:\n",
    "                # Compare to the target values\n",
    "                output_delta = self._layerOutput[index] - target.T\n",
    "                error = np.sum(output_delta**2)\n",
    "                delta.append(output_delta * self.tFuncs[index](self._layerInput[index], True))\n",
    "            else:\n",
    "                # Compare to the following layer's delta\n",
    "                delta_pullback = self.weights[index + 1].T.dot(delta[-1])\n",
    "                delta.append(delta_pullback[:-1, :] * self.tFuncs[index](self._layerInput[index], True))\n",
    "            \n",
    "        # Compute weight deltas\n",
    "        for index in range(self.layerCount):\n",
    "            delta_index = self.layerCount - 1 - index\n",
    "            \n",
    "            if index == 0:\n",
    "                layerOutput = np.vstack([input.T, np.ones([1, lnCases])])\n",
    "            else:\n",
    "                layerOutput = np.vstack([self._layerOutput[index - 1], np.ones([1, self._layerOutput[index - 1].shape[1]])])\n",
    "            \n",
    "            curWeightDelta = np.sum(\\\n",
    "                                 layerOutput[None,:,:].transpose(2, 0 ,1) * delta[delta_index][None,:,:].transpose(2, 1, 0)\\\n",
    "                                 , axis = 0)\n",
    "            \n",
    "            weightDelta = trainingRate * curWeightDelta + momentum * self._previousWeightDelta[index]\n",
    "            \n",
    "            self.weights[index] -= weightDelta\n",
    "            \n",
    "            self._previousWeightDelta[index] = weightDelta\n",
    "        \n",
    "        return error\n",
    "    \n",
    "#normalization function\n",
    "def norm(dizi):\n",
    "    global Maxs, Mins\n",
    "    Maxs = np.amax(dizi,axis=0)\n",
    "    #Maxs = np.array([210,200,50])\n",
    "    Mins = np.amin(dizi,axis=0)\n",
    "    #Mins =np.array([100,30,30])\n",
    "    A = []\n",
    "    for d in dizi:\n",
    "        a = []\n",
    "        for i in range(d.shape[0]):\n",
    "            new = (d[i]-Mins[i])/(Maxs[i]-Mins[i])\n",
    "            a.append(new)\n",
    "        A.append(a)\n",
    "    New = np.array(A)\n",
    "    return New\n",
    "    \n",
    "#sorgu yapma fonksiyonu\n",
    "def Sor(inp):\n",
    "    A = []\n",
    "    a = []\n",
    "    for i in range(inp.shape[0]):\n",
    "        new = (inp[i]-Mins[i])/(Maxs[i]-Mins[i])\n",
    "        a.append(new)\n",
    "    A.append(a)\n",
    "    New = np.array(A)\n",
    "    print(\"normalize edildi: \",New)\n",
    "    deger = bpn.Run(New)\n",
    "    return deger\n",
    "\n",
    "#\n",
    "# If run as a script, create a test object\n",
    "#\n",
    "if __name__ == \"__main__\":\n",
    " \n",
    "    #veri içeri alma\n",
    "    from numpy import genfromtxt \n",
    "    my_data = genfromtxt('winequality-red.csv', delimiter=';',skip_header=1)\n",
    "\n",
    "    train = my_data[:1000,:] #my_data[:1200,:]\n",
    "    test = my_data[1000:,:]\n",
    "    train_input = train[:,:11]\n",
    "    train_target= train[:,11:]\n",
    "    test_input = test[:,:11]\n",
    "    test_target = test[:, 11:]\n",
    "    \"\"\"\n",
    "    print(\"my_data: \",my_data.shape)\n",
    "    print(\"train: \", train.shape)\n",
    "    print(\"test: \", test.shape)\n",
    "    print(\"train_input shape: \",train_input.shape)\n",
    "    print(\"train_target shape: \",train_target.shape)\n",
    "    \"\"\"\n",
    "    lvTarget = norm(train_target)\n",
    "    #lvTarget = train_target/10\n",
    "    lvInput = norm(train_input)\n",
    "    #katman sayısı kadar Transfer Fonksiyonu EKLE\n",
    "    lFuncs = [None, TransferFunctions.tanh, TransferFunctions.linear, TransferFunctions.sgm]\n",
    "    #Katman yapısını belirle\n",
    "    bpn = BackPropagationNetwork((11,12,5,1), lFuncs)\n",
    "    #iterasyon sayısı ve istenilen hata oranı gir\n",
    "    lnMax = 50000 #50000\n",
    "    lnErr = 1e-1  #1e-6 0.1\n",
    "    for i in range(lnMax+1):\n",
    "        err = bpn.TrainEpoch(lvInput, lvTarget,0.02, 0.5)\n",
    "        if i % 5000 == 0 and i > 0: #5000\n",
    "            print(\"Iteration {0:6d}K - Error: {1:0.6f}\".format(int(i/1000), err))\n",
    "        if err <= lnErr:\n",
    "            print(\"İstenilen hata oranına ulaşıldı. Iter: {0}\".format(i))\n",
    "            break     \n",
    "        \n",
    "        \n",
    "    # Display output\n",
    "    \n",
    "    lvOutput = bpn.Run(lvInput)\n",
    "    for i in range(train_input.shape[0]):\n",
    "        print(\"Input: {0} Output: {1} expect: {2}\".format(train_input[i], lvOutput[i],lvTarget[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalize edildi:  [[0.86363636 0.10989011 0.64285714 0.54736842 0.06682578 0.04081633\n",
      "  0.02173913 0.72131148 0.30927835 0.27044025 0.87804878]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.42923947]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sor(np.array([7.5, 0.52, 0.16, 1.9, 0.085, 12, 35, 0.9968, 3.38, 0.62, 9.5]))\n",
    "#Sor(np.array([7.5, 0.52, 0.11, 1.5, 0.079, 11, 39, 0.9968, 3.42, 0.58, 9.6]))\n",
    "Sor(np.array([10.3, 0.32, 0.45, 6.4, 0.073, 5, 13, 0.9976, 3.23, 0.82, 12.6 ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sor(a):\n",
    "    girdi = np.array([a])\n",
    "    print(girdi,'')\n",
    "    inp = norm(girdi)\n",
    "    print(inp,'')\n",
    "    deger = bpn.Run(inp)\n",
    "\n",
    "    return deger"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Sor([7.5     0.52    0.16    1.9     0.085  12.     35.      0.9968  3.38\n",
    "  0.62    9.5   ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
